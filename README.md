# Ctrip_Sentiment_Analysis
爬取携程数据并进行情感分析

- models ：存放与训练模型
- src ：源代码
- data：存放数据

## 爬取数据

本实验的数据来源于**携程**网站，主要通过爬虫技术自动化抓取桂林各大景区的评论信息。数据的获取分为两个阶段：首先抓取景区的基本信息，包括景区名称、链接和等级；然后根据这些信息进一步抓取每个景区的游客评论数据，包括评论时间、IP 属地、评分和评论内容。

### 爬取景点列表
![alt text](assets/README/image.png)
携程景点下的评论数据
url = "https://you.ctrip.com/sight/guilin28/s0-p1.html"
url可以更改为想要爬取的城市的对应url
运行文件`src\get_data\get_sights.py`自动爬取，数据存储到`data\sight_data.csv`中
内容包括：

- **景区名称**：景区的名称。

- **景区链接**：景区在携程网站上的详细页面链接。

- **景区等级**：景区的等级信息，若没有等级信息，则标记为“无等级”。

  可能不会自动停止爬取，最后需要手动停一下

### 爬取景点下的评论
前提：上一步爬取到的景点列表
景区链接获取景区url，定位到评论
景区名称用来给文件命名

运行`src\get_data\total_sight.py`文件，获取每一个景点下的评论信息
数据保存在`data\comment_data`目录下
文件内容：

- **评论时间**：评论发布的时间。
- **IP 属地**：评论用户的IP属地信息。
- **评分**：游客对景区的评分（1-5分）。
- **评论内容**：游客的评论文本

具体操作步骤如下：

1. 读取 `data\sight_data.csv` 中保存的景区名称和链接信息。
2. 逐一访问每个景区的评论页面，抓取页面中的评论数据。
3. 每个景区的评论数据通过分页抓取，直到所有评论被抓取完毕。
4. 将抓取到的评论数据保存为独立的 CSV 文件，文件名包含景区名称和地址。

## 数据预处理
上一步爬取的数据有108163条，但是我需要分析的大概是50000条
需要筛除一部分数据，留下一些高质量的数据

**数据筛选策略：**

根据分析,一个景点最多能爬取3000条数据，也有的景点评论数据很少只有几条，按理来说数据量越多，越值得分析，所以按数据量大小来筛选数据，数据量多的景点优先选择

**预处理策略：**

在情感分析中，最为关键的信息即为评论信息，当然爬取的数据还有包括评论日期和IP属地等信息，但是本项目并没有在时间和位置上做过多的分析，评论日期和IP属地信息对于这个项目来说用处不大。当然当要对评论情感做地域分析时、或想要捕捉时间上的情感变化时，这些信息也是非常重要的。

于是本项目对于筛选出来的数据，剔除了date和IP属地的数据，只留下了评分和评论这两个属性。评论comment作为后续情感分析的重要数据来源，评分可以在错误分析时对情感分析的结果给出辅助信息。

同时本项目使用了微调模型，模型的相应文件已经下载至models文件夹,下载地址：[uer/roberta-base-finetuned-dianping-chinese · Hugging Face](https://huggingface.co/uer/roberta-base-finetuned-dianping-chinese)

`roberta-base-finetuned-dianping-chinese` 是一个经过微调的中文情感分析模型，基于 **RoBERTa**（A Robustly Optimized BERT Pretraining Approach）架构，专门用于 **大众点评（Dianping）** 数据的情感分析任务。

RoBERTa 是 BERT（Bidirectional Encoder Representations from Transformers）模型的一种改进版本，由 Facebook AI 提出。RoBERTa 对 BERT 的训练方法进行了优化，一方面去除 了Next Sentence Prediction (NSP) 任务，在 BERT 中，NSP 用于训练句子对任务，但 RoBERTa 去除了这一任务，并发现去除后性能有所提升。另一方面增加了训练数据量，RoBERTa 使用了比 BERT 更大规模的语料库进行预训练，包括了 160GB 的文本数据，比 BERT 使用的 16GB 数据多了 10 倍。但是，RoBERTa 的预训练过程进行了更长时间的训练，与此同时增强了模型的表示能力。

RoBERTa 被广泛应用于文本分类、情感分析、问答系统等任务。在中文情感分析任务中，RoBERTa 提供了强大的文本理解能力。特别是在针对大规模中文评论数据进行训练后，模型能够更好地捕捉中文句子的情感特征。

其原本处理的数据集是大众点评的数据，查看了数据集之后，发现是csv文件，有两列，都用双引号括起来，第一列是一个数字，猜测是评分，第二列是一段文字，应该是评论内容。

相应地，我想要将我的数据也整理成评分＋评论的csv文件格式，都用双引号括起来。

预处理文件为：`src\pre_process\process_data.py`

预处理后的文件保存在`data\precessed_data`文件夹下

## 情感分析

通过两种不同的情感分析方法进行对比。第一种方法使用中文预训练语言模型（`roberta-base-finetuned-dianping-chinese`），第二种方法使用 `SnowNLP` 库进行情感分析。通过对比这两种方法的分析效果，评估其在中文评论情感分析中的表现。

1.**RoBERTa 微调模型进行情感分析** 

我使用了一个名为 `roberta-base-finetuned-dianping-chinese` 的预训练模型，该模型基于 RoBERTa 结构，并在中文餐饮评论数据集上进行了微调。该模型通过识别评论中的情感关键词，预测评论的情感倾向。该模型支持分类为正面（positive）和负面（negative），并给出情感预测的置信度评分。

**情感分析过程：**

1. 对每条评论文本进行预处理，将其分词并截断为最大 512 个 token。
2. 使用微调后的 RoBERTa 模型进行情感分类，输出正面或负面标签，并计算情感置信度。
3. 保存每条评论的情感标签及对应的置信度评分。

2.**SnowNLP 进行情感分析** 

SnowNLP 是一个开源的中文自然语言处理库，支持中文文本的情感分析。它基于情感词典和统计模型，通过计算情感分数来判断文本的情感倾向。

**情感分析过程：**

1. 通过 `SnowNLP` 对每条评论进行情感分析，计算情感分数（范围为 0 到 1）。
2. 根据情感分数进行二分类：
   - 如果情感分数大于 0.5，则判断为正面（positive）。
   - 否则，判断为负面（negative）。
3. 将分析结果保存为新的 CSV 文件，记录每条评论的情感分类标签。


## 结果

对于每个景区的评论数据，我分别使用 RoBERTa 微调模型和 SnowNLP 库进行情感分析，并将分析结果保存为 CSV 文件。每条评论的分析结果包括以下字段：

- **score**：评论的评分。
- **comment**：评论文本。
- **sentiment_category**：情感分类结果，分为正面（positive）和负面（negative）。
- **sentiment_score**：情感分析模型给出的置信度评分（RoBERTa）或情感分数（SnowNLP）。

#### 对比分析

**1 精度和效果**

- **RoBERTa 微调模型**：由于其预训练的语言模型具有较强的上下文理解能力，它能够更好地捕捉到评论中的情感细节和微妙的情感变化。在复杂的句子和含有双重含义的评论中，RoBERTa 模型能够给出较为准确的情感分类，特别适合处理具有一定复杂度的评论数据。
- **SnowNLP**：作为一种基于规则和情感词典的简易模型，SnowNLP 在大多数情况下能够提供快速的情感分类，但在一些较为复杂或含有隐含情感的评论中，它可能无法给出准确的结果，尤其是中性情感的处理。

**2 运行速度**

- **RoBERTa 微调模型**：由于模型较大且需要进行 GPU 计算，因此在情感分析时会占用较多的计算资源，处理速度相对较慢。
- **SnowNLP**：相比于 RoBERTa，SnowNLP 的运行速度较快，适用于快速处理大量评论数据，特别是在没有 GPU 资源的情况下，SnowNLP 可以较为高效地进行批量处理。



## 结论

本实验通过两种情感分析方法（RoBERTa 微调模型和 SnowNLP）对携程网站桂林景区的评论数据进行了情感分类。实验结果表明：

- **RoBERTa 微调模型** 在情感分类的准确性上具有更强的优势，特别是在处理复杂评论时表现优异。
- **SnowNLP** 在处理大规模数据时更为高效，但其准确性和细节捕捉能力较 RoBERTa 模型稍逊。
