# Ctrip_Sentiment_Analysis
爬取携程数据并进行情感分析

- models ：存放与训练模型
- src ：源代码
- data：存放数据

## 爬取数据

本实验的数据来源于**携程**网站，主要通过爬虫技术自动化抓取桂林各大景区的评论信息。数据的获取分为两个阶段：首先抓取景区的基本信息，包括景区名称、链接和等级；然后根据这些信息进一步抓取每个景区的游客评论数据，包括评论时间、IP 属地、评分和评论内容。

### 爬取景点列表
![alt text](assets/README/image.png)
携程景点下的评论数据
url = "https://you.ctrip.com/sight/guilin28/s0-p1.html"
url可以更改为想要爬取的城市的对应url
运行文件`src\get_data\get_sights.py`自动爬取，数据存储到`data\sight_data.csv`中
内容包括：

- **景区名称**：景区的名称。

- **景区链接**：景区在携程网站上的详细页面链接。

- **景区等级**：景区的等级信息，若没有等级信息，则标记为“无等级”。

  可能不会自动停止爬取，最后需要手动停一下

### 爬取景点下的评论
前提：上一步爬取到的景点列表
景区链接获取景区url，定位到评论
景区名称用来给文件命名

运行`src\get_data\total_sight.py`文件，获取每一个景点下的评论信息
数据保存在`data\comment_data`目录下
文件内容：

- **评论时间**：评论发布的时间。
- **IP 属地**：评论用户的IP属地信息。
- **评分**：游客对景区的评分（1-5分）。
- **评论内容**：游客的评论文本

具体操作步骤如下：

1. 读取 `data\sight_data.csv` 中保存的景区名称和链接信息。
2. 逐一访问每个景区的评论页面，抓取页面中的评论数据。
3. 每个景区的评论数据通过分页抓取，直到所有评论被抓取完毕。
4. 将抓取到的评论数据保存为独立的 CSV 文件，文件名包含景区名称和地址。

## 数据预处理
上一步爬取的数据有108163条，但是我需要分析的大概是50000条
需要筛除一部分数据，留下一些高质量的数据

**数据筛选策略：**

根据分析,一个景点最多能爬取3000条数据，也有的景点评论数据很少只有几条，按理来说数据量越多，越值得分析，所以按数据量大小来筛选数据，数据量多的景点优先选择

**预处理策略：**

在情感分析中，最为关键的信息即为评论信息，当然爬取的数据还有包括评论日期和IP属地等信息，但是本项目并没有在时间和位置上做过多的分析，评论日期和IP属地信息对于这个项目来说用处不大。当然当要对评论情感做地域分析时、或想要捕捉时间上的情感变化时，这些信息也是非常重要的。

于是本项目对于筛选出来的数据，剔除了date和IP属地的数据，只留下了评分和评论这两个属性。评论comment作为后续情感分析的重要数据来源，评分可以在错误分析时对情感分析的结果给出辅助信息。

同时本项目采用了预处理模型，模型的相应文件已经下载至models文件夹

## 评论分析


## 结果
